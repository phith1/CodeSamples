import argparse
import math
import numpy as np
import os
import pandas as pd
import random
import shapefile as sf
from shapely import geometry

from utils import compute_distance as haversine

''' This code generates a list of retailers within a given radius from a given center point. 
    For example: 60km radius from the city of Bhadrak (lat and lon) in Odisha.

    NOTE: 
        It is assumed that you have already narrowed down a list of villages within the area (see villages_in_range())
        as well as created files containing the area's populations (as per the GPW), population densities, and distances
        from the origin. These files can be created using the Georaster package, particularly the pixels_to_csv() and 
        write_ArcGIS_header() functions. 

    Retailers are generated based on the surrounding population:
        - Rural areas are given 1 retailer per village. 
        - Periurban areas are given 1 retailer per 600 people.
        - Urban areas are given 1 retailer per 400 people. 

    NOTE: Cities aren't included in our data, only villages, so I've included a sample arguments below.     
    Bhadrak Centerpoint: 21.0583 86.4658 34.0
    Bhadrak Snapshot Bounds: 
        bhadrak_min_lat = 20.751
        bhadrak_max_lat = 21.365
        bhadrak_min_lon = 86.140 
        bhadrak_max_lon = 86.795

    Runtime arguments: 
    villages -- CSV file containing basic location and market data for villages within area in question.
    aggregate -- CSV file containing data from four files generated by GeoRasterViewer.
    wholesale -- CSV file containing basic data on wholesale markets. 
    block_shapes -- Shapefile for Odisha divided on the Block level. 
    block_names -- CSV file containing data-to-shapefile translations for Districts/Blocks. 
    codebook -- CSV file containing corresponding codes for Blocks/Districts within the naming convention. 

    Output: 
    retailers.csv -- CSV containing a retailer's name, location, closest wholesaler and its distance, urbanicity, and
        the local population served by the retailer. 

    '''


def get_retailer_closest_wholesalers(retailer, wholesalers):
    # Shamelessly pulled from the GeoRasterViewer code because it works really well.

    # Convert the wholesalers into arrays of lats/lons.
    wholesale_lats = wholesalers.Latitude.values
    wholesale_lons = wholesalers.Longitude.values
    wholesale_names = wholesalers.Wholesale_Name.values
    wholesale_ids = wholesalers.Location_ID.values

    # Calculate the distances and prune out the farther ones and isolate variables.
    distances = np.ndarray.flatten(haversine(retailer[0], retailer[1], wholesale_lats, wholesale_lons))
    closest_index = np.argmin(distances)
    closest_distance = distances[closest_index]

    # Consolidate into a dictionary and return
    closest = {
        "Wholesaler": [wholesale_lats[closest_index], wholesale_lons[closest_index]],
        "Wholesaler_Name": wholesale_names[closest_index],
        "Wholesaler_ID": wholesale_ids[closest_index],
        "Distance": closest_distance
    }
    return closest


def main(villages, file_name, aggregate, wholesalers, block_shapes, shapefile_conversion, codes):
    retail_labels = ["ID", "Name", "Block", "District", "Latitude", "Longitude", "Urbanicity",
                     "Closest_Wholesaler", "Wholesaler_Name", "Wholesaler_ID", "Distance"]
    urban_list = []
    periurban_list = []
    rural_list = []
    aggregate['has_retailer'] = False

    # PART ONE: GENERATE RETAILERS BY URBANICITY
    # First let's handle the Urban locations
    urban = aggregate.loc[aggregate["Density"] == 3]
    urban_pop = urban["Population"].sum()
    for i, row in enumerate(urban.itertuples(), 0):
        # Create a retailer for every 350 people
        num_stores = math.floor(row.Population / 350)
        for store in range(num_stores):
            # Randomly generate retailer coords within area boundaries
            lat = random.uniform(row.Lat_Lower, row.Lat_Upper)
            lon = random.uniform(row.Lon_Lower, row.Lon_Upper)

            closest = get_retailer_closest_wholesalers([lat, lon], wholesalers)
            urban_list.append(["", "", "", "", lat, lon, 3, closest["Wholesaler"],
                               closest["Wholesaler_Name"], closest["Wholesaler_ID"], closest["Distance"], ])

    # Create dataframe and set population as mean across urban residents
    urban_retailers = pd.DataFrame(urban_list, columns=retail_labels)
    urban_retailers["Population_Served"] = urban_pop / len(urban_retailers.index)

    # Next are the Periurban locations
    periurban = aggregate.loc[aggregate["Density"] == 2]
    periurban_pop = periurban["Population"].sum()
    for i, row in enumerate(periurban.itertuples(), 0):
        # Create a retailer for every 350 people
        num_stores = math.floor(row.Population / 350)
        for store in range(num_stores):
            # Randomly generate retailer coords within area boundaries
            lat = random.uniform(row.Lat_Lower, row.Lat_Upper)
            lon = random.uniform(row.Lon_Lower, row.Lon_Upper)

            closest = get_retailer_closest_wholesalers([lat, lon], wholesalers)
            periurban_list.append(["", "", "", "", lat, lon, 2, closest["Wholesaler"],
                                   closest["Wholesaler_Name"], closest["Wholesaler_ID"], closest["Distance"], ])

    # Create dataframe and set population as mean across periurban residents
    periurban_retailers = pd.DataFrame(periurban_list, columns=retail_labels)
    periurban_retailers["Population_Served"] = periurban_pop / len(periurban_retailers.index)

    # Last are the Rural locations, where there's one retailer per 400 people OR one per village market in the region.
    rural = aggregate.loc[aggregate["Density"] == 1]
    rural_pop = rural["Population"].sum()

    # First we add one rural retailer for each rural village.
    for i, village in enumerate(villages.itertuples(), 0):
        # Find the corresponding rural block, ignoring if a village is beyond the blocky bounds of the grid. (Rare)
        valid_up = village.Longitude <= rural['Lon_Upper'].max()
        valid_down = rural['Lon_Lower'].min() <= village.Longitude
        valid_left = rural['Lat_Lower'].min() <= village.Latitude
        valid_right = village.Latitude <= rural['Lat_Upper'].max()
        in_bounds = valid_up and valid_down and valid_left and valid_right

        # An empty row indicates a village isn't contained within a rural area.
        row = rural.loc[
            (rural['Lat_Lower'] <= village.Latitude)
            & (village.Latitude <= rural['Lat_Upper'])
            & (rural['Lon_Lower'] <= village.Longitude)
            & (village.Longitude <= rural['Lon_Upper'])
            ]

        # Add the retailer's information to a the list if it's rural and within the region.
        if in_bounds and not row.empty:
            # Create a retailer within that block
            lat = random.uniform(row['Lat_Lower'].values[0], row['Lat_Upper'].values[0])
            lon = random.uniform(row['Lon_Lower'].values[0], row['Lon_Upper'].values[0])

            closest = get_retailer_closest_wholesalers([lat, lon], wholesalers)
            rural_list.append(["", "", "", "", lat, lon, 1, closest["Wholesaler"],
                               closest["Wholesaler_Name"], closest["Wholesaler_ID"], closest["Distance"], ])
            row_index = row.index.values.astype(int)[0]
            rural.loc[row_index, "has_retailer"] = True

    # Then we add one retailer for each rural pixel at or above the population cutoff.
    for i, row in enumerate(rural.itertuples(), 0):
        # If the pixel hasn't had a retailer assigned to it, assign one per 400 people.
        if not row.has_retailer:
            num_stores = math.floor(row.Population / 400)
            for store in range(num_stores):
                # Randomly generate retailer coords within area boundaries
                lat = random.uniform(row.Lat_Lower, row.Lat_Upper)
                lon = random.uniform(row.Lon_Lower, row.Lon_Upper)

                closest = get_retailer_closest_wholesalers([lat, lon], wholesalers)
                rural_list.append(["", "", "", "", lat, lon, 1, closest["Wholesaler"],
                                   closest["Wholesaler_Name"], closest["Wholesaler_ID"], closest["Distance"], ])

    # Create dataframe and set population as mean across rural residents, and combine all three urbanicities!
    rural_retailers = pd.DataFrame(rural_list, columns=retail_labels)
    rural_retailers["Population_Served"] = rural_pop / len(rural_retailers.index)
    retailers = pd.concat([urban_retailers, periurban_retailers, rural_retailers], ignore_index=True, sort=False)

    # PART TWO: Generate Blocks and Districts for each retailer.
    # First we generate the Records(data) and Shapes(coordinates), as well as dicts to hold data.
    block_rec = block_shapes.records()
    block_list = block_shapes.shapes()
    block_dict = {}
    block_externals = {}

    # Then we go through each Shape and Record and toss the data into the DataFrame or dictionaries.
    for shape, rec in zip(block_list, block_rec):
        block_name = rec[5]
        district_name = rec[3]
        combo = district_name + "_" + block_name

        poly = geometry.Polygon([p for p in shape.points])
        poly_ext = geometry.LinearRing(poly.exterior.coords)
        block_dict[combo] = poly
        block_externals[combo] = poly_ext

    # Loop through all retailers and pair each with its corresponding block and district.
    blocks = []
    districts = []
    block_misspelling = shapefile_conversion['Shape_Block'].tolist()
    district_misspelling = shapefile_conversion['Shape_Dist'].tolist()
    for retailer in retailers.itertuples():
        # We need Lat/Lon of the retailer, formatted specifically as Lon/Lat.
        latitude = retailer.Latitude
        longitude = retailer.Longitude
        pinpoint = geometry.Point(float(longitude), float(latitude))

        # Now we loop through the shapes until we find one that the point is within.
        for shape in block_dict.keys():
            if block_externals[shape].contains(pinpoint):
                divisions = shape.split("_")
                district_name = divisions[0]
                block_name = divisions[1]

                # If District isn't viable, find its equivalent name:
                if district_name in district_misspelling:
                    for mismatch in shapefile_conversion.itertuples():
                        if district_name == mismatch.Shape_Dist:
                            district_name = mismatch.Data_Dist
                # If Block isn't viable, find its equivalent name:
                if block_name in block_misspelling:
                    for mismatch in shapefile_conversion.itertuples():
                        if block_name == mismatch.Shape_Block:
                            block_name = mismatch.Data_Block

                # Then append both to the corresponding lists and break out.
                blocks.append(block_name)
                districts.append(district_name)
                break

        # Now we use a for-else to handle if we don't have a match within any of the block polygons.
        # In this case, we match our point to the block with the closest external/border ring.
        else:
            # We create a dummied point and block/district to hold and update data.
            closest_point = geometry.Point(0, 0)
            found_block = ""
            found_district = ""

            # Loop through the blocks and figure out which external point is closest to our retailer.
            for shape in block_externals.keys():
                # Get the coordinate of the closest point of a given block outline.
                exterior = block_externals[shape]
                projection = exterior.project(pinpoint)
                iter_nearest = exterior.interpolate(projection)

                # Compare and update if closer than saved point/block data.
                if pinpoint.distance(closest_point) > pinpoint.distance(iter_nearest):
                    divisions = shape.split("_")
                    closest_point = iter_nearest
                    found_block = divisions[1]
                    found_district = divisions[0]

            # If District/Block isn't viable, find their equivalents:
            if found_district in district_misspelling:
                for mismatch in shapefile_conversion.itertuples():
                    if found_district == mismatch.Shape_Dist:
                        found_district = mismatch.Data_Dist

            if found_block in block_misspelling:
                for mismatch in shapefile_conversion.itertuples():
                    if found_block == mismatch.Shape_Block:
                        found_block = mismatch.Data_Block

            # Then we append both found names to the list.
            blocks.append(found_block)
            districts.append(found_district)

    # PART THREE: Save Blocks/Districts before doing lookups for ID Code generation
    retailers['Block'] = blocks
    retailers['District'] = districts

    retailers['code'] = retailers.District + "_" + retailers.Block
    for code in retailers.groupby('code').groups.items():
        # Set index to 1 and isolate dist_block codes and indices of relevant wholesales.
        index = 1
        unique_code = code[0]
        retailers_with_code = list(code[1])

        # Access the ID directory and get the four digits code set up.
        combo = codes.loc[codes["Combo"] == unique_code]
        district_code = combo.iloc[0]['District_Code']
        block_code = combo.iloc[0]['Block_Code']
        block = combo.iloc[0]['Block']

        # Now we assign the full code, 7 (wholesale market) + dist/block codes + 3 digits for index.
        for retailers_index in retailers_with_code:
            full_id = '9{:02}{:02}{:03}'.format(district_code, block_code, index)
            retailers.loc[retailers_index, 'ID'] = full_id
            retailers.loc[retailers_index, 'Name'] = "{}_{:03}".format(block, index)
            index = index + 1

    # Finalize file and print breakdown by Urbanicity.
    retailers = retailers.drop(columns='code')
    retailers.to_csv("{}_retailers_{}.csv".format(file_name, len(wholesalers)), index=False)
    print("Retailers by Urbanicity:\n=========================\nTotal {}\n{}\n".format(
        len(retailers.index),
        retailers['Urbanicity'].value_counts(),
    ))


if __name__ == '__main__':
    parser = argparse.ArgumentParser('Produces a list of retailers based on population surrounding a center village.')
    parser.add_argument('village_data_file', type=str, help='The path to the input csv file of village markets data.')
    parser.add_argument('aggregate', type=str, help="The path to the population aggregate csv file.")
    parser.add_argument('wholesale', type=str, help="The path to the wholesaler csv file.")
    parser.add_argument('block_shape', type=str, help="The path to the block shape file.")
    parser.add_argument('block_names', type=str, help="The path to the block-to-data translation file.")
    parser.add_argument('codebook', type=str, help="The path to the Location ID codebook.")
    args = parser.parse_args()

    villages = pd.read_csv(
        args.village_data_file,
        dtype={
            'Location_ID': str,
            'Village_Name': str,
            'District_Name': str,
            'Block': str,
            'Market_Frequency': str,
            'Longitude': float,
            'Latitude': float,
        },
    )
    file_name = os.path.basename(args.village_data_file)[:-4]
    aggregate_file = pd.read_csv(args.aggregate)
    wholesaler_file = pd.read_csv(args.wholesale)
    block_data = sf.Reader(args.block_shape)
    block_fixes = pd.read_csv(args.block_names)
    codebook = pd.read_csv(args.codebook)

    main(villages, file_name, aggregate_file, wholesaler_file, block_data, block_fixes, codebook)
